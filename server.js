const path = require("path");
const express = require("express");
const app = express();
// Substitua seu SYSTEM_PROMPT por este:
const SYSTEM_PROMPT = `
VocÃª Ã© um assistente em portuguÃªs, claro e objetivo, que responde em **Markdown estilizado**.
Use **tÃ­tulos curtos**, **listas**, **negrito**, **itÃ¡lico** e **emojis** para deixar a resposta agradÃ¡vel e escaneÃ¡vel.
Sempre que possÃ­vel:
- Comece com um tÃ­tulo curto (##) + 1 emoji.
- Use listas com marcadores.
- Feche com uma frase curta de convite Ã  interaÃ§Ã£o.

### Escopo
1) Dicas prÃ¡ticas para **minimizar danos ambientais** (reduÃ§Ã£o de resÃ­duos, reciclagem, economia de Ã¡gua/energia, mobilidade sustentÃ¡vel, consumo consciente, etc.).
2) InformaÃ§Ãµes sobre o **stand do grupo** na â€œFeira do Conhecimentoâ€ (propÃ³sito do projeto, como funciona a IA e o site, convite para visitar).
3) InformaÃ§Ãµes sobre o **ColÃ©gio Militar Dom Pedro II**; se faltar dado especÃ­fico, seja honesto e sugira fontes oficiais.

### Regra especial â€” â€œparticipantes do grupoâ€
Quando perguntarem sobre o **grupo da Feira do Conhecimento**, responda SEMPRE neste formato (Markdown):

## ðŸ‘¥ Participantes do grupo
- **Victor Marques** â€” Desenvolvimento da IA ðŸ¤–  
- **Felipe Fernandes** â€” Desenvolvimento do site ðŸŒ  
- **Davi Fontenele, Eduardo Neirelli, Lucas Mesquita e Guilherme Monton** â€” Pesquisas bibliogrÃ¡ficas ðŸ“š

*(Se precisar de mais informaÃ§Ãµes sobre o projeto, fico Ã  disposiÃ§Ã£o!)*

Importante:
- NÃ£o invente dados. Se nÃ£o souber, diga que nÃ£o possui a informaÃ§Ã£o e sugira canais oficiais.
`;

require("dotenv").config();
const OpenAI = require("openai");
const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

app.use(express.json());
app.use(express.static(path.join(__dirname, "public")));

app.get("/", (_req, res) => {
  res.sendFile(path.join(__dirname, "public", "index.html"));
});

app.post("/api/chat", async (req, res) => {
  try {
    const { messages } = req.body ?? {};
    console.log("Body recebido:", JSON.stringify(req.body)); // debug

    if (!Array.isArray(messages)) {
      console.error("Erro 400: 'messages' nÃ£o Ã© array");
      return res.status(400).json({ error: "Campo 'messages' precisa ser um array." });
    }
    if (!process.env.OPENAI_API_KEY) {
      console.error("Erro 500: OPENAI_API_KEY ausente");
      return res.status(500).json({ error: "OPENAI_API_KEY nÃ£o configurada." });
    }

    const resp = await client.responses.create({
      model: "gpt-4o-mini",
      input: [{ role: "system", content: SYSTEM_PROMPT.trim()}, ...messages]
    });

    const reply = (resp.output_text || "").trim();
    if (!reply) {
      console.error("Erro 502: Resposta vazia da OpenAI");
      return res.status(502).json({ error: "Resposta vazia da OpenAI" });
    }

    console.log("âœ… OpenAI respondeu com texto (tamanho):", reply.length);
    res.json({ reply });
  } catch (e) {
    // log rico no servidor
    const status = e?.status || 500;
    console.error("âŒ /api/chat falhou â€” status:", status);
    console.error("Mensagem:", e?.message || e);
    if (e?.stack) console.error("Stack:", e.stack);

    // devolve msg pro front ver
    res.status(status).json({ error: e?.message || "Falha ao chamar a OpenAI" });
  }
});


const PORT = process.env.PORT || 3000;
app.listen(PORT, () => console.log(`On :${PORT}`));








